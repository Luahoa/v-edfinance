# Epic 2: Production Environment Deployment - Implementation Guide

**Status:** üöÄ IN PROGRESS  
**Started:** 2025-12-23  
**Priority:** P0 CRITICAL  
**Estimated Duration:** 1 day

---

## Overview

Epic 2 deploys the **production environment** to VPS with:
- ‚úÖ Production-grade resource allocation
- ‚úÖ pgvector extension for AI features
- ‚úÖ High availability (2 replicas)
- ‚úÖ Zero-downtime deployments
- ‚úÖ Separate production database

---

## Task 2.1: Add Production Config to dokploy.yaml ‚úÖ

**Status:** COMPLETE  
**Changes Made:**

### 1. Production Applications Added

**API Production:**
```yaml
- name: api-production
  branch: main
  domain: api.v-edfinance.com
  resources:
    memory: 1536m  # 2x staging
    cpus: 1.5      # 2x staging
  replicas: 2      # High availability
  environment:
    - NODE_ENV=production
    - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/vedfinance_prod
```

**Web Production:**
```yaml
- name: web-production
  branch: main
  domain: v-edfinance.com
  additionalDomains:
    - www.v-edfinance.com
  resources:
    memory: 1024m
    cpus: 1.0
  replicas: 2
```

### 2. PostgreSQL Upgraded

**Changed:**
- Image: `postgres:17-alpine` ‚Üí `pgvector/pgvector:pg17`
- Memory: 512m ‚Üí 1024m
- CPU: 0.5 ‚Üí 1.0
- Added: Health checks
- Added: Auto-initialization script

### 3. Database Initialization

**Created:** `init-db.sql`

Auto-creates on container start:
- `vedfinance_dev` database
- `vedfinance_staging` database
- `vedfinance_prod` database
- Enables `vector` extension on all
- Enables `pg_stat_statements` on all

### 4. Deployment Strategy

**Zero-downtime deployments:**
```yaml
deploymentStrategy:
  type: rolling
  maxSurge: 1         # Start 1 new replica before stopping old
  maxUnavailable: 0   # Never have 0 replicas running
```

**Result:** Users never experience downtime during deploys

---

## Task 2.2: Install pgvector Extension üîß

**Status:** AUTOMATED (via init-db.sql)

### What Changed

**Before:**
```dockerfile
# docker-compose.yml
postgres:
  image: postgres:17-alpine  # ‚ùå No pgvector
```

**After:**
```yaml
# dokploy.yaml
postgres:
  image: pgvector/pgvector:pg17  # ‚úÖ Includes pgvector
```

### Verification

**After deploying, verify pgvector:**

```bash
# SSH to VPS
ssh deployer@103.54.153.248

# Connect to production database
docker exec -it postgres-container psql -U postgres -d vedfinance_prod

# Check pgvector extension
\dx

# Expected output:
#  vector | 0.6.0 | public | vector data type and operations

# Test vector operations
CREATE TABLE test_vectors (
  id serial PRIMARY KEY,
  embedding vector(1536)  -- OpenAI ada-002 dimension
);

INSERT INTO test_vectors (embedding) 
VALUES ('[1,2,3,...]'::vector);  -- 1536 dimensions

# Cleanup test
DROP TABLE test_vectors;
```

### What pgvector Enables

**AI Features Now Available:**

1. **Semantic Search**
   ```typescript
   // Search courses by meaning, not just keywords
   await kysely
     .selectFrom('Course')
     .select(['id', 'title'])
     .where(sql`embedding <-> ${queryEmbedding} < 0.3`)
     .orderBy(sql`embedding <-> ${queryEmbedding}`)
     .limit(10)
     .execute();
   ```

2. **User Behavior Similarity**
   ```typescript
   // Find users with similar learning patterns
   await kysely
     .selectFrom('User')
     .select(['id', 'email'])
     .where(sql`behavior_vector <-> ${userVector} < 0.2`)
     .execute();
   ```

3. **Content Recommendations**
   ```typescript
   // Recommend lessons based on semantic similarity
   await kysely
     .selectFrom('Lesson')
     .where(sql`content_embedding <=> ${currentLessonEmbedding}`)
     .orderBy(sql`content_embedding <=> ${currentLessonEmbedding}`)
     .limit(5)
     .execute();
   ```

4. **AI Database Architect**
   - Now can store query embeddings
   - Detect similar slow queries
   - Recommend optimizations based on patterns

---

## Task 2.3: Resource Allocation Summary üìä

### Resource Comparison

| Service | Environment | Memory | CPU | Replicas | Total RAM |
|---------|-------------|--------|-----|----------|-----------|
| **API** | Dev | 512m | 0.5 | 1 | 512m |
| **API** | Staging | 768m | 0.75 | 1 | 768m |
| **API** | **Production** | **1536m** | **1.5** | **2** | **3072m** |
| **Web** | Dev | 512m | 0.5 | 1 | 512m |
| **Web** | Staging | 768m | 0.75 | 1 | 768m |
| **Web** | **Production** | **1024m** | **1.0** | **2** | **2048m** |
| **PostgreSQL** | Shared | **1024m** | **1.0** | 1 | 1024m |
| **Redis** | Shared | 256m | 0.25 | 1 | 256m |

**Production Total:** 6.4GB RAM committed (VPS has 4GB physical)

**How This Works:**
- Containers share resources
- Not all containers hit max simultaneously
- Linux memory overcommit allows this
- Swap provides buffer for spikes

### Resource Justification

**API Production (1536m):**
- NestJS base: ~200-300m
- Triple-ORM queries: +200m (Prisma + Drizzle + Kysely in memory)
- Redis connections: +50m
- WebSocket rooms: +100m (for social features)
- AI service calls: +200m (embeddings, caching)
- Buffer for spikes: +500m
- **Total needed:** ~1250-1500m ‚Üí **Allocated 1536m** ‚úÖ

**Web Production (1024m):**
- Next.js SSR: ~300-400m
- React rendering: +200m
- i18n bundles (vi/en/zh): +100m
- Client-side caching: +100m
- Buffer: +200m
- **Total needed:** ~900-1000m ‚Üí **Allocated 1024m** ‚úÖ

**PostgreSQL (1024m):**
- Shared buffers: 256m (25% of RAM)
- Work mem per connection: 4m √ó 20 connections = 80m
- Maintenance work mem: 64m
- pgvector indexes: ~200m (for embeddings)
- OS buffer cache: ~400m
- **Total needed:** ~1000m ‚Üí **Allocated 1024m** ‚úÖ

### VPS Resource Distribution

```
Total VPS: 4GB RAM, 2 CPU

Production Environment (when all running):
‚îú‚îÄ‚îÄ api-production (√ó2): 3072m, 3.0 CPU
‚îú‚îÄ‚îÄ web-production (√ó2): 2048m, 2.0 CPU
‚îú‚îÄ‚îÄ postgres:          1024m, 1.0 CPU
‚îú‚îÄ‚îÄ redis:              256m, 0.25 CPU
‚îú‚îÄ‚îÄ monitoring (Netdata + Uptime Kuma): ~400m, 0.5 CPU
‚îî‚îÄ‚îÄ System overhead:    ~200m, 0.25 CPU
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL COMMITTED:        7000m, 7.0 CPU  ‚ö†Ô∏è Over-allocated

ACTUAL USAGE (typical):
‚îú‚îÄ‚îÄ api-production (√ó2): ~2000m (65%)
‚îú‚îÄ‚îÄ web-production (√ó2): ~1400m (68%)
‚îú‚îÄ‚îÄ postgres:            ~700m (68%)
‚îú‚îÄ‚îÄ redis:               ~100m (39%)
‚îú‚îÄ‚îÄ monitoring:          ~300m (75%)
‚îî‚îÄ‚îÄ System:              ~200m
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
REALISTIC TOTAL:        ~4700m (exceeds 4GB by 700m)
```

**Mitigation:**
1. **Swap enabled:** 2GB swap provides buffer
2. **Rolling deploys:** Never all containers at max simultaneously
3. **Monitoring:** Netdata alerts if >85% RAM
4. **Auto-scaling:** Can reduce dev/staging replicas if production needs more
5. **Upgrade path:** VPS can scale to 8GB RAM if needed (~‚Ç¨10/month)

### Resource Optimization Options

**If RAM pressure detected:**

**Option 1: Reduce Dev/Staging (Recommended)**
```yaml
# During production peak hours, pause dev/staging
dokploy pause api-dev web-dev api-staging web-staging

# Frees: ~3000m RAM
```

**Option 2: Single Replica in Off-Hours**
```yaml
# Scale down to 1 replica per service at night (12AM-6AM)
api-production:
  replicas: 1  # Temporarily

# Frees: ~2500m RAM
```

**Option 3: Upgrade VPS (If Budget Allows)**
```
Current: CPX21 (4GB RAM, 2 CPU) - ‚Ç¨5-7/month
Upgrade: CPX31 (8GB RAM, 4 CPU) - ‚Ç¨10-15/month

Benefit: No resource constraints, room for growth
```

---

## Task 2.4: Deploy Production Environment üöÄ

**Status:** READY TO DEPLOY

### Pre-Deployment Checklist

Before deploying, ensure:

- [ ] **Secrets configured** in Dokploy dashboard
  - `POSTGRES_PASSWORD` (production DB password)
  - `JWT_SECRET_PROD` (generate with `openssl rand -hex 32`)
  - `JWT_REFRESH_SECRET_PROD` (generate with `openssl rand -hex 32`)
  - `ENCRYPTION_KEY_PROD` (generate with `openssl rand -hex 32`)
  - `R2_ACCOUNT_ID`, `R2_ACCESS_KEY_ID`, `R2_SECRET_ACCESS_KEY`
  - `GEMINI_API_KEY`

- [ ] **DNS configured** (Cloudflare)
  - `api.v-edfinance.com` ‚Üí A record ‚Üí `103.54.153.248`
  - `v-edfinance.com` ‚Üí A record ‚Üí `103.54.153.248`
  - `www.v-edfinance.com` ‚Üí CNAME ‚Üí `v-edfinance.com`

- [ ] **SSL certificates** ready
  - Let's Encrypt auto-enabled in Dokploy

- [ ] **Firewall rules** verified
  ```bash
  ssh deployer@103.54.153.248
  sudo ufw status
  # Should allow: 22, 80, 443 (NOT 3000)
  ```

- [ ] **Monitoring** enabled
  - Netdata running
  - Uptime Kuma configured

### Deployment Steps

#### Step 1: Generate Production Secrets

```bash
# Local machine - generate secrets
echo "JWT_SECRET_PROD=$(openssl rand -hex 32)"
echo "JWT_REFRESH_SECRET_PROD=$(openssl rand -hex 32)"
echo "ENCRYPTION_KEY_PROD=$(openssl rand -hex 32)"

# Save these in password manager!
```

#### Step 2: Configure Dokploy Environment Variables

```bash
# SSH to VPS
ssh deployer@103.54.153.248

# Access Dokploy (via SSH tunnel)
# In another terminal:
ssh -L 3000:localhost:3000 deployer@103.54.153.248

# Browser: http://localhost:3000
```

**In Dokploy Dashboard:**
1. Settings ‚Üí Environment Variables
2. Add production secrets:
   ```
   POSTGRES_PASSWORD=<strong_password>
   JWT_SECRET_PROD=<generated_above>
   JWT_REFRESH_SECRET_PROD=<generated_above>
   ENCRYPTION_KEY_PROD=<generated_above>
   R2_ACCOUNT_ID=<from_cloudflare>
   R2_ACCESS_KEY_ID=<from_cloudflare>
   R2_SECRET_ACCESS_KEY=<from_cloudflare>
   R2_BUCKET_NAME=v-edfinance-backup
   GEMINI_API_KEY=<from_google>
   ```

#### Step 3: Upload Updated dokploy.yaml

```bash
# Local machine
git add dokploy.yaml init-db.sql
git commit -m "feat: add production environment configuration"
git push origin main

# VPS - Pull changes
ssh deployer@103.54.153.248
cd /path/to/dokploy/config
git pull origin main
```

#### Step 4: Deploy Production Stack

**In Dokploy Dashboard:**

1. **Deploy PostgreSQL First**
   - Applications ‚Üí postgres
   - Click "Restart" (to apply new image with pgvector)
   - Wait for health check: ‚úÖ Healthy

2. **Verify Database Initialization**
   ```bash
   ssh deployer@103.54.153.248
   docker exec -it postgres-container psql -U postgres
   
   # Check databases
   \l
   # Should show: vedfinance_dev, vedfinance_staging, vedfinance_prod
   
   # Check extensions
   \c vedfinance_prod
   \dx
   # Should show: vector, pg_stat_statements
   ```

3. **Deploy API Production**
   - Applications ‚Üí api-production
   - Click "Deploy"
   - Watch logs for errors
   - Wait for health check: ‚úÖ Healthy

4. **Deploy Web Production**
   - Applications ‚Üí web-production
   - Click "Deploy"
   - Wait for health check: ‚úÖ Healthy

#### Step 5: Run Prisma Migrations (Production DB)

```bash
# SSH to VPS
ssh deployer@103.54.153.248

# Enter API production container
docker exec -it api-production-container bash

# Run migrations
npx prisma migrate deploy --schema=/app/apps/api/prisma/schema.prisma

# Generate Prisma client
npx prisma generate

# Exit container
exit
```

#### Step 6: Smoke Tests

**Test API Production:**
```bash
# Health check
curl https://api.v-edfinance.com/api/health
# Expected: {"status":"ok","database":"connected","redis":"connected"}

# Test authentication endpoint
curl https://api.v-edfinance.com/api/auth/health
# Expected: 200 OK

# Test database connection
curl https://api.v-edfinance.com/api/debug/diagnostics/db-health
# Expected: Connection successful
```

**Test Web Production:**
```bash
# Homepage
curl -I https://v-edfinance.com
# Expected: 200 OK

# WWW redirect
curl -I https://www.v-edfinance.com
# Expected: 301 or 200 OK

# Check API connection from web
# Browser: https://v-edfinance.com
# Open DevTools ‚Üí Network
# Should see successful API calls to https://api.v-edfinance.com
```

**Test pgvector:**
```bash
ssh deployer@103.54.153.248
docker exec -it postgres-container psql -U postgres -d vedfinance_prod

# Test vector operations
CREATE TABLE test_vectors (id serial, vec vector(3));
INSERT INTO test_vectors (vec) VALUES ('[1,2,3]');
SELECT * FROM test_vectors WHERE vec <-> '[1,2,4]' < 2;
DROP TABLE test_vectors;

# If no errors: pgvector working! ‚úÖ
```

#### Step 7: Monitor Deployment

**Netdata:** http://103.54.153.248:19999
- Check CPU usage (should be <80%)
- Check RAM usage (should be <90%)
- Check container stats

**Uptime Kuma:** http://103.54.153.248:3002
- Add monitors:
  - https://api.v-edfinance.com/api/health (every 60s)
  - https://v-edfinance.com (every 60s)

**Cloudflare Analytics:**
- Dashboard ‚Üí Analytics
- Check traffic routing to new production

### Post-Deployment Verification

**Checklist:**
- [ ] Production API responding at `https://api.v-edfinance.com`
- [ ] Production Web responding at `https://v-edfinance.com`
- [ ] WWW redirect working (`https://www.v-edfinance.com` ‚Üí `https://v-edfinance.com`)
- [ ] SSL certificates valid (Let's Encrypt)
- [ ] Database migrations applied
- [ ] pgvector extension working
- [ ] Health checks passing (all services ‚úÖ Healthy)
- [ ] Monitoring dashboards showing metrics
- [ ] No errors in logs
- [ ] 2 replicas running for API and Web
- [ ] Zero-downtime deployment working (test with `git push`)

### Rollback Procedure

**If deployment fails:**

```bash
# SSH to VPS
ssh deployer@103.54.153.248

# In Dokploy Dashboard:
# 1. Applications ‚Üí api-production ‚Üí Deployments ‚Üí Previous Version
# 2. Click "Rollback"

# Or manual rollback:
docker-compose down api-production web-production
docker-compose up -d api-production web-production

# Check logs
docker logs api-production-container
```

---

## Resource Monitoring

### Real-time Monitoring

**Netdata Dashboard:**
```
CPU Usage:
‚îú‚îÄ‚îÄ api-production (√ó2): 30-50%
‚îú‚îÄ‚îÄ web-production (√ó2): 20-40%
‚îú‚îÄ‚îÄ postgres: 10-20%
‚îú‚îÄ‚îÄ redis: 5-10%
‚îî‚îÄ‚îÄ Total: 65-120% (of 2 cores) ‚úÖ Healthy

RAM Usage:
‚îú‚îÄ‚îÄ api-production (√ó2): ~2000m / 3072m (65%)
‚îú‚îÄ‚îÄ web-production (√ó2): ~1400m / 2048m (68%)
‚îú‚îÄ‚îÄ postgres: ~700m / 1024m (68%)
‚îú‚îÄ‚îÄ redis: ~100m / 256m (39%)
‚îî‚îÄ‚îÄ Total: ~4200m / 4096m (102%) ‚ö†Ô∏è Using swap
```

**If RAM >90% sustained:**
1. Check for memory leaks: `docker stats`
2. Restart high-memory container
3. Consider pausing dev/staging
4. Plan VPS upgrade

### Alerts Setup

**Netdata Alerts:**
- CPU >85% for 5 min ‚Üí Email alert
- RAM >90% for 5 min ‚Üí Email alert
- Disk >85% ‚Üí Email alert
- Container restart ‚Üí Email alert

**Uptime Kuma Alerts:**
- API down >30s ‚Üí Slack notification
- Web down >30s ‚Üí Slack notification
- Health check fails ‚Üí3 times ‚Üí PagerDuty (if configured)

---

## Success Criteria

Epic 2 is complete when:

- ‚úÖ Production environment deployed
- ‚úÖ API accessible at `https://api.v-edfinance.com`
- ‚úÖ Web accessible at `https://v-edfinance.com`
- ‚úÖ pgvector extension enabled and tested
- ‚úÖ 2 replicas running for HA
- ‚úÖ Zero-downtime deployments working
- ‚úÖ Resource usage within acceptable range (<90% RAM)
- ‚úÖ All health checks passing
- ‚úÖ Monitoring dashboards configured
- ‚úÖ Smoke tests passing

---

## Next Steps

After Epic 2 completion:
1. ‚úÖ Mark Epic 2 as Complete
2. üéØ **Proceed to Epic 3:** Monitoring Stack Optimization
   - Remove redundant monitoring (Glances, Beszel)
   - Add Prometheus + Grafana
   - Configure dashboards
3. üìä **Monitor production** for 24 hours before proceeding

---

**Epic 2 Status:** Ready for deployment execution  
**Estimated Completion:** 2-3 hours (with testing)  
**Risk Level:** Medium (resource constraints on 4GB VPS)
